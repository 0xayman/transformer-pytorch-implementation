{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0261aa-72e0-4fcb-84c3-31e8ff8ba645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e0261aa-72e0-4fcb-84c3-31e8ff8ba645",
    "outputId": "af789a0a-2ee5-4aa6-e4ba-f6a23c7d99ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() # Check if gpu is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078a05fb-0a70-4082-8b0a-c01f54a337ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "078a05fb-0a70-4082-8b0a-c01f54a337ed",
    "outputId": "bea51a94-cf55-484c-e98f-21015bf10ab1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df87ad63-bdbc-4dda-9555-ae07552b8226",
   "metadata": {
    "id": "df87ad63-bdbc-4dda-9555-ae07552b8226"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4285bf-80ef-4d4b-9847-88ab110a8da5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d4285bf-80ef-4d4b-9847-88ab110a8da5",
    "outputId": "fca535d4-2906-4923-b750-6b4317373ea0"
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "d_model = 32 # d_model\n",
    "h = 4 # number of heads\n",
    "d_k = d_model // h\n",
    "dropout = 0.1\n",
    "n_layers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef83d2a0-a3c0-442c-8175-338b875f90d9",
   "metadata": {
    "id": "ef83d2a0-a3c0-442c-8175-338b875f90d9"
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(d_k, d_k, bias=False)\n",
    "        self.W_k = nn.Linear(d_k, d_k, bias=False)\n",
    "        self.W_v = nn.Linear(d_k, d_k, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # perform scaled dot-production attention\n",
    "        Q = self.W_q(q) # q @ Wq -> (seq_len, d_k) @ (d_k, d_k) => query (seq_len, d_k)\n",
    "        K = self.W_k(k)   # k @ Wq -> (seq_len, d_k) @ (d_k, d_k) => key (seq_len, d_k)\n",
    "        V = self.W_v(v) # v @ Wq -> (seq_len, d_k) @ (d_k, d_k) => value (seq_len, d_k)\n",
    "\n",
    "        # The attention score will be calculated using the below formula\n",
    "        # Attention(Q, K, V) = softmax((Q @ k.T) / sqrt(d_k)) @ V\n",
    "        # Dimentions:\n",
    "        # Q (seq_len, d_k) @ K.T (d_k, seq_len) -> (seq_len, seq_len) : will call this QK for reference\n",
    "        # Apply the mask to QK to obtain masked_QK\n",
    "        # attention(Q, K, V) = (masked_QK / sqrt(d_k)) @ V\n",
    "        # The mask have dimentions (seq_len, seq_len)\n",
    "\n",
    "        # Calculate (Q @ K.T) / sqrt(d_k)\n",
    "        # print(Q.shape, K.shape)\n",
    "        attention_scores = (Q @ K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        # print(attention_scores.shape, mask.shape)\n",
    "        # Apply the mask\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        # Apply Softmax\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "        # calculate attention scores\n",
    "        attention_scores = attention_scores @ V\n",
    "\n",
    "        # apply dropout\n",
    "        attention_scores = self.dropout(attention_scores)\n",
    "        return attention_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "416586ee-b975-43ea-b6de-e3c79809bb20",
   "metadata": {
    "id": "416586ee-b975-43ea-b6de-e3c79809bb20"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attention_heads = nn.ModuleList([AttentionHead() for _ in range(h)]) # Create (h) heads, h = number of heads\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # Split q, k and v to (h) chunks to be sent in parallel to the (h) heads\n",
    "        q_chunks = torch.chunk(q, 4, dim=-1)\n",
    "        k_chunks = torch.chunk(k, 4, dim=-1)\n",
    "        v_chunks = torch.chunk(v, 4, dim=-1)\n",
    "        attention_scores = torch.cat(\n",
    "            [\n",
    "                h(\n",
    "                    q_chunks[idx],\n",
    "                    k_chunks[idx],\n",
    "                    v_chunks[idx],\n",
    "                    mask)\n",
    "                for idx, h in enumerate(self.attention_heads)],\n",
    "            dim=-1\n",
    "        ) # attention_scores has dimentions (seq_len, d_model)\n",
    "\n",
    "        attention_scores = self.W_o(attention_scores) # attention_scores (seq_len, d_model) @ Wo (d_model, d_model) -> (seq_len, d_model)\n",
    "        attention_scores = self.dropout(attention_scores) # Apply dropout\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69549dba-df0a-4dd7-8f00-3499a16da46a",
   "metadata": {
    "id": "69549dba-df0a-4dd7-8f00-3499a16da46a"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * d_model, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66278010-f06e-4686-b5d3-9eb000e2a9e8",
   "metadata": {
    "id": "66278010-f06e-4686-b5d3-9eb000e2a9e8"
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a single encoder layer.\n",
    "    Note that the Encoder consists of N identical layers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.multi_head_self_attention = MultiHeadAttention()\n",
    "        self.ffwd = FeedForwardNet()\n",
    "        self.lnorm1 = nn.LayerNorm(d_model)\n",
    "        self.lnorm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = x + self.lnorm1(self.multi_head_self_attention(x, x, x, mask))\n",
    "        x + x + self.lnorm2(self.ffwd(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c63c739-62b3-4922-864c-f23e515e6562",
   "metadata": {
    "id": "4c63c739-62b3-4922-864c-f23e515e6562"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.Sequential(*[EncoderBlock() for _ in range(n_layers)])\n",
    "        self.lnorm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x, mask)\n",
    "\n",
    "        x = self.lnorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0201149-be3c-47d2-aca1-bf3a12ac5d1b",
   "metadata": {
    "id": "a0201149-be3c-47d2-aca1-bf3a12ac5d1b"
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.multi_head_self_attention = MultiHeadAttention()\n",
    "        self.lnorm1 = nn.LayerNorm(d_model)\n",
    "        self.multi_head_cross_attention = MultiHeadAttention()\n",
    "        self.lnorm2 = nn.LayerNorm(d_model)\n",
    "        self.ffwd = FeedForwardNet()\n",
    "        self.lnorm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, o, encoder_output, src_mask, tgt_mask):\n",
    "        self_attention_output = self.multi_head_self_attention(o, o, o, tgt_mask)\n",
    "        o = o + self.lnorm1(self_attention_output)\n",
    "        cross_attention_output = self.multi_head_cross_attention(o, encoder_output, encoder_output, src_mask) # query, key ,value\n",
    "        o = o + self.lnorm2(cross_attention_output)\n",
    "        ffwd_out = self.ffwd(o)\n",
    "        o = o + self.lnorm3(ffwd_out)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e3f0d73-ec7a-4ad0-a5c6-404e51b70b30",
   "metadata": {
    "id": "0e3f0d73-ec7a-4ad0-a5c6-404e51b70b30"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder_layers = nn.Sequential(*[DecoderBlock() for _ in range(n_layers)])\n",
    "        self.lnorm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, o, encoder_ouput, src_mask=None, tgt_mask=None):\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            o = decoder_layer(o, encoder_ouput, src_mask, tgt_mask)\n",
    "\n",
    "        o = self.lnorm(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bd1e7c1-2d4b-4a09-abef-5ed3f808b6b2",
   "metadata": {
    "id": "9bd1e7c1-2d4b-4a09-abef-5ed3f808b6b2"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model) # (vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(vocab_size, d_model) # (seq_len, d_model)\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.projection_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        # (batch_size, seq_len, d_model)\n",
    "        src = self.token_embed(src) + self.pos_embed(src)\n",
    "        encoder_output = self.encoder(src)\n",
    "        return encoder_output\n",
    "\n",
    "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
    "        # (batch_size, seq_len, d_model)\n",
    "        tgt = self.token_embed(tgt) + self.pos_embed(tgt)\n",
    "        decoder_output = self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
    "        return decoder_output\n",
    "\n",
    "    def project(self, x):\n",
    "        # (batch_size, seq_len, vocab_size)\n",
    "        return self.projection_layer(x)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
